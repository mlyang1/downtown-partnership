{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import metapack as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display \n",
    "from dtcv import get_image\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context('notebook')\n",
    "mp.jupyter.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>San Diego Downtown Homless Computer Vision Package</h1>\n",
       "<p><code>sandiegodata.org-downtown_cv-5</code> Last Update: 2019-09-13T04:52:01</p>\n",
       "<p><em>Files and code for analyzing San Diego downtown homelessness  data with computer vision</em></p>\n",
       "<p>This dataset collects records related to a conversion of 5 years of paper maps\n",
       "that record positions of homeless sleepers in downtown San Diego. The San Diego\n",
       "Regional Data Library is <a href=\"http://downtown-homelessness.sandiegodata.org/\">converting these paper maps to a digital\n",
       "form</a> with a manual process that\n",
       "uses an image annotation tool, and theses annotations can be used to train\n",
       "computer vision algorithms to georeference maps and recognize handwritten marks.</p>\n",
       "<p>These datasets link to map urls and annotations, for three kinds of annotations:</p>\n",
       "<ul>\n",
       "<li>Ground Control Points, which identify the map image locations for known intersections, linking image coordinates ( in pixels ) to geographic coordinates.</li>\n",
       "<li>Image locations of handwritten marks and the number written in the mark.</li>\n",
       "<li>File annotations, for other handwritten notes such as the temperature and presence of rain. </li>\n",
       "</ul>\n",
       "<h2>More Information:</h2>\n",
       "<ul>\n",
       "<li><a href=\"https://www.sandiegodata.org/2019/09/computer-vision-for-greater-good/\">Blog Post</a>. For more discussion about the GCP and handwritten marks, and the tasks in volved\n",
       "in developing computer vision algorithms for these data, see our recent blog\n",
       "post on the subject.</li>\n",
       "<li><a href=\"https://nbviewer.jupyter.org/github/sandiegodata-projects/homelessness/blob/master/datasets/sandiegodata.org-downtown_cv/notebooks/Template%20Matching%20Clusters.ipynb\">Clustering Notebook</a>. For some examples of using OpenCV to extract and match templates, to georeference maps, see the Templates and Clustering Jupyter Notebook].</li>\n",
       "<li><a href=\"https://nbviewer.jupyter.org/github/sandiegodata-projects/homelessness/blob/master/datasets/sandiegodata.org-downtown_cv/notebooks/Extract%20Marks.ipynb\">Extract Marks Notebook</a>. For examples of extracting ( but not recognizing ) handwritten marks, see this notebook. </li>\n",
       "</ul>\n",
       "<h2>Developer notes</h2>\n",
       "<p>After anotation JSON files are copied into S#, the list of S# urls must be\n",
       "updated. To refresh the list of urls run</p>\n",
       "<pre><code>$  bin/update_s3.sh &lt;s3-profile&gt;\n",
       "</code></pre>\n",
       "<h2>Contacts</h2>\n",
       "<ul>\n",
       "<li><strong>Wrangler</strong> <a href=\"mailto:eric@civicknowledge.com\">Eric Busboom</a>, <a href=\"http://civicknowledge.com\">Civic Knowledge</a></li>\n",
       "</ul>\n",
       "<h2>Resources</h2>\n",
       "<ul>\n",
       "<li><strong> <a href=\"data/gcp.csv\">gcp</a></strong>. Ground control points</li>\n",
       "<li><strong> <a href=\"data/intersection_regions.csv\">intersection_regions</a></strong>. Polygon transformations for each the intersections of each map</li>\n",
       "<li><strong> <a href=\"data/intersections.csv\">intersections</a></strong>. List of intersections.</li>\n",
       "<li><strong> <a href=\"data/file_annotations.csv\">file_annotations</a></strong>. File annotations on count files</li>\n",
       "<li><strong> <a href=\"data/counts.csv\">counts</a></strong>. Annotation position, types and counts of handwritten marks</li>\n",
       "</ul>"
      ],
      "text/plain": [
       "# San Diego Downtown Homless Computer Vision Package\n",
       "`sandiegodata.org-downtown_cv-5` Last Update: 2019-09-13T04:52:01\n",
       "\n",
       "_Files and code for analyzing San Diego downtown homelessness  data with computer vision_\n",
       "\n",
       "\n",
       "This dataset collects records related to a conversion of 5 years of paper maps\n",
       "that record positions of homeless sleepers in downtown San Diego. The San Diego\n",
       "Regional Data Library is [converting these paper maps to a digital\n",
       "form](http://downtown-homelessness.sandiegodata.org/) with a manual process that\n",
       "uses an image annotation tool, and theses annotations can be used to train\n",
       "computer vision algorithms to georeference maps and recognize handwritten marks.\n",
       "\n",
       "These datasets link to map urls and annotations, for three kinds of annotations:\n",
       "\n",
       "* Ground Control Points, which identify the map image locations for known intersections, linking image coordinates ( in pixels ) to geographic coordinates.\n",
       "* Image locations of handwritten marks and the number written in the mark.\n",
       "* File annotations, for other handwritten notes such as the temperature and presence of rain. \n",
       "\n",
       "## More Information:\n",
       "\n",
       "* [Blog Post](https://www.sandiegodata.org/2019/09/computer-vision-for-greater-good/). For more discussion about the GCP and handwritten marks, and the tasks in volved\n",
       "in developing computer vision algorithms for these data, see our recent blog\n",
       "post on the subject.\n",
       "* [Clustering Notebook](https://nbviewer.jupyter.org/github/sandiegodata-projects/homelessness/blob/master/datasets/sandiegodata.org-downtown_cv/notebooks/Template%20Matching%20Clusters.ipynb). For some examples of using OpenCV to extract and match templates, to georeference maps, see the Templates and Clustering Jupyter Notebook].\n",
       "* [Extract Marks Notebook](https://nbviewer.jupyter.org/github/sandiegodata-projects/homelessness/blob/master/datasets/sandiegodata.org-downtown_cv/notebooks/Extract%20Marks.ipynb). For examples of extracting ( but not recognizing ) handwritten marks, see this notebook. \n",
       "\n",
       "\n",
       "## Developer notes\n",
       "\n",
       "After anotation JSON files are copied into S#, the list of S# urls must be\n",
       "updated. To refresh the list of urls run\n",
       "\n",
       "    $  bin/update_s3.sh <s3-profile>\n",
       "\n",
       "\n",
       " \n",
       "\n",
       "## Contacts\n",
       "\n",
       "* **Wrangler** [Eric Busboom](mailto:eric@civicknowledge.com), [Civic Knowledge](http://civicknowledge.com)\n",
       "\n",
       "## Resources\n",
       "\n",
       "* ** [gcp](data/gcp.csv)**. Ground control points\n",
       "* ** [intersection_regions](data/intersection_regions.csv)**. Polygon transformations for each the intersections of each map\n",
       "* ** [intersections](data/intersections.csv)**. List of intersections.\n",
       "* ** [file_annotations](data/file_annotations.csv)**. File annotations on count files\n",
       "* ** [counts](data/counts.csv)**. Annotation position, types and counts of handwritten marks\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pkg = mp.jupyter.open_package()\n",
    "#pkg = mp.jupyter.open_source_package()\n",
    "pkg = mp.open_package('http://library.metatab.org/sandiegodata.org-downtown_cv-5.zip')\n",
    "\n",
    "pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3><a name=\"resource-counts\"></a>counts</h3><p><a target=\"_blank\" href=\"http://library.metatab.org/sandiegodata.org-downtown_cv-5.zip#data%2Fcounts.csv\">http://library.metatab.org/sandiegodata.org-downtown_cv-5.zip#data%2Fcounts.csv</a></p><table>\n",
       "<tr><th>Header</th><th>Type</th><th>Description</th></tr><tr><td>image_url</td><td>string</td><td>Map image URL</td></tr> \n",
       "<tr><td>cx</td><td>integer</td><td>X value of the center of the circle region, in pixels</td></tr> \n",
       "<tr><td>cy</td><td>integer</td><td>Y value of the center of the circle region in pixels</td></tr> \n",
       "<tr><td>r</td><td>integer</td><td>Radius of the circle region, in pixels</td></tr> \n",
       "<tr><td>type</td><td>string</td><td>Type of sleeper: Individual, Vehicle or Structure</td></tr> \n",
       "<tr><td>count</td><td>string</td><td>Count of sleepers</td></tr> </table>"
      ],
      "text/plain": [
       "<Resource: metadata.csv 32:1 root.datafile data/counts.csv ['counts', 'Annotation position, types and counts of handwritten marks', '']>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pkg.resource('counts'))\n",
    "counts = pkg.resource('counts').dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take a few minutes; it will download about 330 images and save them to the /tmp directory\n",
    "counts['image'] = counts.image_url.apply(get_image)\n",
    "\n",
    "counts['count'] = pd.to_numeric(counts['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa993d04390>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def crop(row):\n",
    "    \"\"\"Crop the handwritten mark, and hopefully the shape around it, from the image\"\"\"\n",
    "    x, y, r = row.cx, row.cy, row.r\n",
    "    \n",
    "    r = int(r*1.0)\n",
    "   \n",
    "    return row.image[y-r:y+r, x-r:x+r ]\n",
    "\n",
    "plt.imshow(crop(counts.iloc[60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faae933bf28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numbers = []\n",
    "\n",
    "def invert(img):\n",
    "    # Convert the img to grayscale \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) \n",
    "    r = cv2.resize(gray, (100,100))\n",
    "    _, tr = cv2.threshold (r, 70, 255, cv2.THRESH_BINARY_INV);\n",
    "    return tr\n",
    "\n",
    "for  name, row in  counts.iterrows():\n",
    "    if row['count'] is not None and not np.isnan(row['count']) and row['count'] < 10 :\n",
    "        numbers.append((row['count'], invert(crop(row))))\n",
    "    \n",
    "print(len(numbers))\n",
    "plt.imshow(numbers[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "epochs = 12\n",
    "\n",
    "\n",
    "# the data, split between train and test sets\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# input image dimensions\n",
    "#img_rows, img_cols = 28, 28\n",
    "\n",
    "\n",
    "X = np.array([e[1] for e in numbers])\n",
    "y = np.array([e[0] for e in numbers])\n",
    "\n",
    "num_classes = len(np.unique(y))+1\n",
    "\n",
    "l  = len(X)\n",
    "train_l = int(l*.9)\n",
    "x_train = X[:train_l]\n",
    "y_train = y[:train_l]\n",
    "\n",
    "x_test = X[train_l:]\n",
    "y_test = y[train_l:]\n",
    "\n",
    "img_rows, img_cols = x_train[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (3737, 100, 100, 1)\n",
      "3737 train samples\n",
      "416 test samples\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/eric/anaconda3/envs/data36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 3737 samples, validate on 416 samples\n",
      "Epoch 1/12\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
